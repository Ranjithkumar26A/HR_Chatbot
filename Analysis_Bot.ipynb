{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a22a4d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain.schema import HumanMessage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6dc8eccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AIzaSyAllRscPiikg7TOQqRvTkLkUKCWHMHAiDs'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()\n",
    "os.environ['GOOGLE_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "776a5c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",temperature=.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "313ca1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "Excel_data = pd.read_excel(r'C:\\Python_practice\\GENAI\\HR_Employee_Data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ee8d472",
   "metadata": {},
   "outputs": [],
   "source": [
    "Analysis_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "    \"\"\"You are a smart, friendly, and highly focused data analysis assistant. You analyze the provided Excel HR dataset and respond clearly and precisely in natural language.\n",
    "\n",
    "Excel dataset: {Excel_data}\n",
    "\n",
    "GUIDELINES:\n",
    "1. Use ONLY the data directly present in the Excel dataset above for ALL responses.\n",
    "2. You are allowed and expected to perform simple data analysis tasks on the dataset such as sorting, filtering, aggregation (e.g., finding the highest salary, average, counts).\n",
    "3. If the user asks for the highest paid employee, find the employee with the maximum salary by analyzing the dataset and respond with a clear sentence like: \"Saran is the highest paid employee with a salary of $20,000.\"\n",
    "4. If the requested information is not present or cannot be determined from the data, respond clearly: \"This information is not available in the dataset.\"\n",
    "5. Do NOT guess, infer, or fabricate data outside what is given.\n",
    "6. Answer ONLY what the user asks. Do not provide extra summaries or charts unless requested.\n",
    "7. For greetings or general chit-chat, respond politely and ask if you can help with the dataset.\n",
    "\n",
    "Your goal is to help users quickly get exactly the information they need from the dataset by reading and analyzing it.\n",
    "\"\"\"),\n",
    "    (\"placeholder\", \"{message}\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8aaad8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_chain = Analysis_prompt | LLM\n",
    "\n",
    "Question = \"Who is the highest paid employee\"\n",
    "\n",
    "User_input = {\n",
    "\n",
    "    \"message\" : [Question],\n",
    "    \"Excel_data\": Excel_data\n",
    "}\n",
    "\n",
    "Response = response_chain.invoke(User_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c86eeb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ann Beck is the highest paid employee with a salary of $118618.68.\n"
     ]
    }
   ],
   "source": [
    "print(Response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GENAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
